Alex Worden's Career Accomplishments and Experience In Detail

Division Virtual Reality Inc. - Software Engineer

Prior to starting my professional Career, I was an avid programmer. I started programming at age 8 in 1980 on personal computers, learning Basic, Pascal, and 6502 assembly language. I created a software company at age 14 and built and sold several software applications including commercial graphics rendering for advertising, computer games, and an economics simulation for educational use. I studied Computer Science with a concentration in Artificial Intelligence at Leeds University, UK and obtained a 1st class degree with honors. 

I started my career in Bristol the UK as a Software Engineer at a Virtual Reality startup called Division, which built the world's first commercial fully immersive VR system. I worked on a small team of 4 engineers. I developed an interactive world-simulation engine that allowed the user to create and interact with a virtual world. This was in essence a game-engine with user-programmable interactions and events that could be applied to objects in the virtual world. Some equivalent software systems today are Minecraft and Roblox. I built an animation engine that was based upon time as opposed to key-frames to allow for real-time rendering of the virtual environment on various hardware platforms with different levels of performance. I was solely responsible for the design and development of an immersive user interface developer library and a set of immersive world-authoring tools that allowed the user to edit the virtual environment while they are in the virtual environment in real-time. I built immersive UI components using the C programming language but I implemented an object oriented paradigm using C structs and function pointers. The object oriented UI component library of widgets and layout managers allowed for widgets to be combined and extended. The UI layouts used a hierarchical structure similar to other UI libraries, but in 3D and allowed for multiple users to interact with them simultaneously. Callbacks could be added to the widgets to invoke external functionality in the simulation engine or with external systems. 

I moved to the USA in the San Francisco Bay Area with Division and took a new role as a customer facing engineer building customer integrations for companies including NASA, Applied Materials, General Motors, GE, Bechtel, Boeing, McDonnell Douglas, Dana, and Harley Davidson. I built an astronaut training simulation for NASA to train EVA operations on the space shuttle. I built a tool to enable the rapid disassembly and reassembly of a virtual mechanical engine assembly which was used by Harley Davidson to train their production mechanics on prototype engine designs. I built a simulation of a microchip wafer fabrication machine to allow Applied Materials to identify microscopic contamination of particles from parts that affected the quality of their microchips. I integrated Java to the C based VR software to allow a customer's systems to integrate from any platform with a JVM. This was one of the first versions of Java 1.1 which was a new technology at the time. 

WebLogic (Acquired by BEA, then acquired by Oracle)
===================================================
I joined a startup in San Francisco called WebLogic which built one of the first Java web servers. I was initially responsible for writing API documentation and building tutorials and developer examples which helped with the rapid customer adoption of the web server, beating the competition. Within six months, I joined the Servlet Engine team as a customer centric engineer as part of the new customer centric engineering team. I became an expert in Java, developing and extending the capabilities of the WebLogic Server. I added new methods for session persistence and management that integrates with the existing object-oriented design and session management interfaces. I added new capabilities to the Java Server Pages (JSP) transpiler written in ANTLR. I was promoted to be the team lead for the customer-centric-engineering team with ~12 other developers building custom extensions and new product capabilities for customers. I spent multiple years helping 100’s of customers scale their systems and making improvements to the WebLogic Server. 

Wells Fargo
===========
I joined a small team at Wells Fargo to completely re-implement their online banking system in WebLogic. I started working at Wells Fargo as a contractor and later joined as a full time employee for a total of 6 years. The Wells Fargo webapp backend interfaced with multiple backend secure banking system services, which gave me an early exposure to SOA / DDD system design before it was a recognized industry practice. I optimized the user sign-on experience from 12+ seconds to under 2 seconds by refactoring multiple backend service calls to execute in parallel. 
At Wells Fargo, I designed and developed a splash-page marketing framework configurable at runtime to deliver personalized offers to customers that generated $20 million in loan leads in the first 60 days of release. 
I developed the first Wells Fargo mobile app, as an embedded customized web-view. 
I designed and developed a framework to financially optimize sending SMS messages to customers. 

Verizon Wireless
================
I worked at Verizon Wireless as a Senior Engineer where I developed a Business Process Management (BPM) system to allow Verizon to coordinate the installation of 5G wireless antenna's across the USA. I developed a no-code/low-code user interface framework to allow web forms to be defined and data collected. The forms could also be converted to interactive PDFs and printed. The framework was object-oriented using a hierarchy of widgets and layout containers that could be interpreted so the desired format of a web-form or a PDF-form. I also optimized the Database queries to be 10x faster by looking at SQL query plans. I also refactored and improved the software architecture to be more maintainable by breaking it up into domain-oriented modules. 

Google
======
I worked at Google in San Francisco on the "Vault" team which built "legal discovery" capabilities into the "Google Apps For Work" product suite and allowed searching and compiling archives across all documents and email owned by an enterprise. Vault was used to compile definitive archives for legal disputes. I refactored and improved the system design that used Google Web Toolkit (GWT) to provision the web interface. I developed a system integration design and project plan to incorporate a legacy email system into the Vault search. The challenge was to search across combined and overlapping emails from two disparate sources of corporate email contexts. I designed a solution to allow the interleaving of search results from multiple pagination cursors that each referenced large data sources. 

General Electric
================
I worked at General Electric (GE) in their Software Center of Excellence in San Ramon. I accomplished the following: 
* I was one of the first engineers hired and defined the hiring and interview process to build the engineering organization from 20 to over 800 high caliber engineers in 9 months. 
* I was promoted to Principal Architect overseeing 20+ projects building IoT Big Data Asset Performance Monitoring (APM) projects across GE's business verticals, including Oil and Gas, Power and Water, Digital Energy, Healthcare, and Aviation. 
* I led a Platform Team to maintain and extend the service broken and several Platform Services (PaaS) that accelerated the development of GE's Industrial Internet projects. 
* I collaborated with executives from each of GE's verticals to determine how Machine Learning and IoT could be utilized to improve their business operations. The term "Industrial Internet" was coined at GE to refer to the many projects that I worked on. 
* I oversaw the architectural design and implementation of 10+ projects. I led multiple "tiger teams" to develop proof-of-concept projects including: 
   * I conceived and led the design and implementation of a "Service Broker" framework similar to Cloud Foundry to allow teams to host and share their multi-tenant PaaS analytic and data services with other teams at GE. 
   * I developed project templates to allow teams to rapidly create new projects based upon maven archetypes.
   * I developed a cloud-native system on AWS to manage and coordinate a network of electric vehicle (EV) charging stations. It allowed GE's EV chargers to share their location and availability, then allow drivers to see which charging stations were available, reserve them, monitor and control them and plan their route. I collaborated with the firmware engineers and introduced the use of Google Protobuf to define the protocol between the firmware and the software systems. We build mobile apps and web apps to provide access for multiple categories of end-users including drivers, administrators, charger owners, and maintenance engineers. 
   * I developed a configuration and monitoring system to model deep-sea blowout preventers (BOP). My design utilized XML to model the configuration of the BOPs so that existing XML editors could be used - a scrappy but effective strategy that enabled the project to be built very rapidly. Once the BOP configuration was defined, the software system could keep track of key metrics and facilitate tracking which components were used and which needed to be replaced or maintained. This increased safety and reduced the deployment time for a maintenance ship from days to hours. These ships cost $500K per day so the savings per year across a fleet of ships were very significant. 
   * I designed and developed a software system to track the maintenance and use of GE Aviation's jet engines over their lifetime. It gathered usage data from each engine and predicted the lifespan of limited-life parts in each engine, which can  over 7000 parts and can cost over $1 million to service off the wing. The system ran Monte Carlo simulations to determine the service intervals needed for each engine and which parts were likely to fail. This allowed GE to determine where to invest R&D in order to increase the lifespan of the parts and reduce the maintenance costs. The system also tracked which airframes the engines were used on across their service life, and which routes those planes flew, which had a significant effect on the engine service intervals necessary. 

Intelligent Financial
=====================
I co-founded the company "Intelligent Financial" with Jim Schmid, an executive Director from GE. They built a SaaS product that allows financial advisors to win clients by creating custom financial portfolio proposals. The system allowed the financial advisor to enter the client's existing financial portfolio, their risk tolerance, and their financial goals. The system uses Monte Carlo simulations against a large pre-processed database of historical financial data to determine which financial instruments could allow the client to achieve or exceed their financial goals with less or similar risk. The system then generates a white-labeled custom portfolio proposal that is tailored to the client's risk tolerance and financial goals in a fraction of the time. This reduces the proposal generation time from multiple days to under 30 minutes, allowing financial advisors to manage and win many more clients for their business. 
* I designed and implemented the system architecture and software systems on AWS using Spring Boot, Java, and PostgreSQL DB. 
* I built a client prospecting system that allowed financial advisors to share a custom link with prospective clients, inviting them to enter their financial portfolio and goals. The system allowed the financial advisor to track the progress of the prospect and follow up with them. 
* I built a user license management system that allowed financial institutions to purchase and manage user licenses and make them available to their financial advisors. It was incorporated with Stripe payments to allow for credit card payments and recurring billing. 
* I built a system to manage organizational configurations, white-labeled branding, user entitlements, and financial instrument data. The system allowed financial umbrella institutions to define limits and provide legal disclaimers for their financial advisors. 


Bigfoot Biomedical (Acquired by Abbott Labs)
============================================

I joined Bigfoot Biomedical as Director of Engineering and was promoted to Senior Director of Engineering after 3 years. I was asked by a Senior Director called Alan Schachtely from GE to join "Bigfoot Biomedical", in order to establish the engineering organization at Bigfoot Biomedical. 
   * I built the engineering team up over 4 years to a total of 5 teams and over 40 people. Some of the best engineers from GE followed me to Bigfoot Biomedical. 
   * At Bigfoot Biomedical, my teams built two commercial products for type-1 and type-2 diabetes. The products were classified as class-3 and class-2 medical devices. They started from a clean slate, and we were able to rapidly design a cloud-native system on Amazon Web Services (AWS) that included a React Native mobile app on iOS and Android that communicated with firmware on the hardware device using Google Protobuf. The mobile app connected the local system to Bigfoot's cloud services, which allowed family members and/or physicians to monitor the health of the person with diabetes on both a webapp (built using React / Typescript) and a version of the React mobile app that was tailored for monitoring. The cloud services were built to be multi-tenant from the start and used Java, Spring Boot, PostgreSQL DB, AWS DynamoDB, Kinesis, and Kafka. My teams used a domain-driven-design (DDD) from the outset, which allowed them to rapidly build and scale the system without the overhead and scalability issues of a typical startup monolith.  
   * I developed a custom agile software development methodology with my team to be compliant with IEC62304 standards and based upon the “AAMI 2012 TIR45 Guidance on the use of AGILE practices in the development of medical device software”. I collaborated with my team and the business stakeholders to develop a light-weight agile working methodology that delivered everything necessary to meet FDA standards but also allowed the team to move fast and innovate. 
   * I collaborated with the VP of Engineering to define a schema in codeBeamer to capture the Hazard Analysis artifacts and trace the identified Harms, Hazards, and their mitigations to product requirements, implementation stories, and verification tests. I also collaborated with an industry expert consultant to incorporate aspects of STPA (System-Theoretic Process Analysis) into the Hazard Analysis SOP to complement the traditional FMEA (Failure Modes and Effects Analysis). STPA is a top-down approach to identifying risk from potential harms and defining their causes as opposed to a bottom up approach of considering the effects of failures in components of the system. 
   * I have continued to evolve these working practices over the rest of my career, where I have shown a track-record for transforming engineering teams and cultures to have predictable high performance and empower engineers to grow and deliver their best work. 
   * I collaborated with engineering, product management, quality management, and the business stakeholders to select an ALM tool called "codeBeamer" to manage the development of the product and generate the requirements traceability documents necessary to meet FDA compliance. I owned the company-wide configuration of codeBeamer. The configuration allowed the definition of "user needs" and "business goals", tracing to specific "product requirements". It supported "hazard analysis" and the definition of risk mitigation requirements. The engineering team worked from high-level system designs that traced to product requirements and implementation stories that built and traced to high-level system designs. Requirements at all levels of the traceability matrix were linked to test definitions and the test results were recorded for each, providing an overview of the verification status of each requirement and specification. 
   * I developed an efficient system based upon an extension of JUnit that could document our verification tests and auto-generate verification test reports that traced to requirements in order to meet FDA and IEC62304 standards. 
   * I mentored and grew two lead engineers into engineering managers, who ran two of my teams. 
   * I led a strategy to build multi-tenant systems based on my learnings from GE, which allowed the teams to share the use of hosted services during development and testing. This greatly simplified and accelerated development and testing of our distributed systems. 
   * I drove the strategy and design of a product verification framework that integrated Bigfoot's hardware devices, mobile applications running on target mobile phones, cloud services, and simulated user's physiology. The system was linearly scalable by adding "test rigs” of hardware and mobile phones that would connect to a central test coordination server and self-configure in order to process tests in parallel that are part of a test suite. The test rigs would download the necessary versions of software in order to execute tests, run the tests, then report test results back to the test coordination service. The test coordination service would then generate a report of the test results and trace them to the requirements that were being verified. This system allowed the engineering team to rapidly verify code changes that were part of a pull request even prior to code review. This allowed the team to catch bugs early and fix them before they were merged into the main branch, where they could affect other developers.
   * I researched and worked with product management to define a strategy to integrate Bigfoot’s Electronic Health Records (EHR) with existing health care systems that use HL7 and FHIR protocols. I gained a first principles understanding of HIPAA regulations w.r.t. the disclosure of patient’s protected health information (PHI) to covered entities and the security standards required to handle the data. 
Bigfoot Biomedical was acquired by Abbott Labs in 2023. 

Rocket Lawyer
=============
I joined Rocket Lawyer as Director of Engineering, leading their engineering teams in North America and Mexico. My role was effectively "Head of Engineering" and at times I reported to the CEO where there was no CTO in place. 
   * I built the engineering organization up to over 40 engineers and fostered a high-performing agile engineering culture similar to what I had developed at Bigfoot Biomedical. I carried over many of the useful aspects of my FDA-compliant engineering processes. I collaborated with the lead engineers to document Rocket Lawyer's multiple software systems, and put processes in place to continue to maintain the documentation and enable design review of their new high level system designs. My engineering practices created a higher level of collaboration amongst engineers, and allowed teams to understand, reuse, and integrate with systems and architectures from other teams. This system documentation was later used to raise investment capital by providing technical documentation for the due-diligence activities. 
   * At Rocket Lawyer, I developed a technical strategy and execution plan to merge and migrate 3 disparate product platforms running in the US, UK, and EU into one global product platform. The strategy allowed for the gradual migration of live customers, and the immediate conversion of new customers to the target systems while minimizing disruption to Rocket Lawyer's most valuable customers. The main challenges were to migrate legal document templates across systems, and to migrate customer data. I collaborated with product management and the business stakeholders to make a hard decision to go forward with a reduced set of legal documents that were supported on the new system. New customers would only have access to the smaller set of document templates that had been created for the new templating software. 
   
Scenario description of the Platform Unification project at Rocket Lawyer: One example of a difficult decision that we had to make was at Rocket Lawyer when I was responsible for defining a strategy to transition the business to a single platform from their 3 current platforms running in the UK, EU, and US. The goal was to migrate the legacy US system to the newer EU system while minimizing any potential disruption to the business and customers. One of the fundamental customer-facing dilemmas was that the US produced 10x the revenue of the EU and had 100x the variety of legal document templates, which were in a legacy format. Migrating the 100’s of document templates to the new template format would take years given the complexity and lack of human resources available. I collaborated with product management and the CEO to analyze the situation, identify and estimate the scope of implementing potential solutions and their impact in order to make an informed decision. I learned that the business had wisely identified and implemented the document templates that were responsible for ~80% of revenue generation and most frequently used templates. After careful consideration, we made the difficult decision to adopt a hybrid approach to integrate the new document template system with the reduced set of legal documents into the US system.  New US customers would only see the smaller set of new document templates. Grand-fathered-in customers would be able to access previously created legacy documents and use legacy document templates for a limited period - the EOL date for legacy templates TBD. Any new document templates that were available and equivalent to legacy templates would be used for new document creation. I created an implementation strategy that would gradually merge the systems to the same platform by componentizing aspects of the systems that could be embedded and ultimately phase-out the legacy equivalent components. My teams had already started building DDD oriented components for document generation and e-signatures, so the strategy was to integrate these into the US system. This allowed us to have customer facing impact ASAP, while the technical challenges of hosting and account merging could proceed in the background. The strategy accounted for new customer experiences and legacy customers on the same US system. I presented the strategy to the CEO and VPE and it was approved. I worked with my teams on a technical design and estimation of scope of implementation. I created a near-term execution plan to integrate the new components and deliver customer-facing value, and also planned a longer-term plan to address the platform integration needs of the system. New customers would have access to the smaller set of documents but with a better user experience while still delivering +80% of the previous capabilities. It was a challenging decision because it involved balancing the needs of the business with the desire to provide a seamless experience for all customers. Aligning the business on one platform would allow the business to deliver new and enhanced features at a faster pace with the same engineering resources. This decision had a significant impact on the direction of the project and the teams involved. It allowed us to start thinking about restructuring the engineering organization in order to support the unified global product platform. 

   * Shortly after I started working at Rocket Lawyer, I conducted a survey with every engineer to understand where improvements to engineering tools and practices could maximize productivity. By asking engineers to quantify how they were spending time on activities other than product development, I determined that the most impact could be gained by building a CI/CD pipeline, and streamlining the production release management process. My Platform Team worked with DevOps to build a comprehensive CI/CD framework based on Kubernetes, Helm, and Docker deployed in Google Cloud Platform (GPC). I empowered the team to determine the needs and goals of the CI/CD system and we designed a system to meet them all. This included the consistent generation and deployment of all environments from individual and shared development environments, demo environments, QA, staging, and production environments. This was achieved using a configuration-as-code paradigm, where every deployment to every environment was performed consistently. Teams were able to build and deploy to production multiple times per day. My teams experienced and worked around a new set of problems of coordination, version control, and quality that arise with highly streamlined production deployments. 
   * I managed the QA teams at Rocket Lawyer and led the coordination of release management. I fixed the previous bottlenecks in production releases by empowering QA leads to have control over the level of complexity in a planned release. Releases of feature-based changes were packaged and planned in a daily release management scrum meeting. My process unblocked the release-train that had been halted for 2 months and ultimately allowed multiple releases per week to be coordinated with high quality and high confidence. This resulted in minimized production issues and disruptions to the business and customers. 
   * At Rocket Lawyer, I managed the Data Engineering team, where I introduced modern Data Warehouse technologies such as Snowflake, Apache Airflow, and Kafka. 
   * I led my Data Engineering Team to build an streaming event data pipeline using Apache Kafka and event consumers to track discrete user experience events from both the backend systems and frontend. We built an event consumer that computed real-time user experience monitoring statistics by tracking the intervals between specific discrete events for each user. This Asset Performance Management (APM) data was used to identify user-drop-off points in our UI flows and identify where we could improve system performance and reliability. The system was also integrated with the Amplitude Customer Data Platform (CDP). 
   * The Data Engineering team served several business stakeholders and I managed their priorities. They included the Business Intelligence Team, the Marketing Team, the Product Management Team, and the Sales Team. 
   * My Application Platform Team built APIs and services to offer white-labeled experiences to affiliate members of our client customer's organizations. 
   * I designed a system to enable affiliate clients to offer account-signup to their customers. In the case of the customer AARP, they wanted to offer Rocket Lawyer as a service to their 50 million members. Initially, the product management team specified requirements to allow affiliate clients to specify and manage lists of eligible users and their email addresses in order for Rocket Lawyer to send sign-up invitations. I worked with product management to clearly define the higher level goals and objectives of the project. I was then able to propose an alternative solution that met the business needs but was more scalable and manageable. My design allowed AARP to retrieve a "Signed URL" for each of their members via a new API to claim an account with specific privileges. Rocket Lawyer previously used the end-user's email address domain to recognize new users as an employee of a client customer company in order to receive the Rocket Lawyer entitlements. Since members of organizations like AARP do not have a common email domain, I designed an innovative solution to solve this problem. My team worked with AARP engineers and were able to integrate a solution into their website within 1 week. The solution involved AARP's website generating a unique URL for each of their members to claim an account with Rocket Lawyer. The URL contained a unique token that was signed by AARP's private key. When the user clicked on the URL, they were redirected to Rocket Lawyer's website where the token was verified using AARP's public key. The token contained the user's email address and the privileges they were entitled to. This allowed Rocket Lawyer to recognize the user as an AARP member and provide them with the correct entitlements. This solution was a win-win for both Rocket Lawyer and AARP. It allowed AARP to manage their member's entitlements and allowed Rocket Lawyer to scale to support millions of AARP members. 
   * At Rocket Lawyer, my teams built an "affiliate member management" system allowing Rocket Lawyer customers to offer Rocket Lawyer membership services as an "employee benefit" to their employees. 
   * At Rocket Lawyer, my Platform Team built a configurable customer entitlement system that stored an end-user's entitlements and capabilities in the system. This allowed for multiple levels of membership and for the user-interface to understand which feature a user has access to, the value of those features, and which features to suggest they could add to their account. 
   * At Rocket Lawyer, I conceived of and designed a "group configuration management service" that could store hierarchical nodes of inheritable configurations. This system solved many issues related to management of configurations across the many aspects of the product. Configurations were able to be easily persisted in a centralized location, with minimal engineering effort to make them dynamically modifiable at runtime. Configurations were able to be defined for groups on nodes in the hierarchy, allowing for members of an affiliate to be given a custom experience, and for sub-groups to also inherit a default experience and apply overrides. This system was used to configure white-labeled experiences, entitlements, and a group's domain data and settings. This also enabled an admin user interface to see and configure all configurable data in one coherent and comprehensive data store. The service provided an streamlined repository for developers to store configuration data without needing to build their own persistence implementation. At the same time, their new configurations were stored in a hierarchy that corresponded to the rest of the system's conceptual grouping of users and organizations, and was ensured to be dynamically modifiable at runtime. 
   * My teams added SSO and OIDC integration for their clients' end-user customers to log into Rocket Lawyer using their own company credentials. 
   * My teams built a self-service API portal using APIGEE for Rocket Lawyer client customers to sign-up. The API portal needed to be integrated with Rocket Lawyer's existing identity management system and APIGEE tokens had to be exchanged for Rocket Lawyer access tokens. 
   * My teams built a multi-tenant micro-service framework capable of rapidly setting up tenancies for development, test cases, client sandboxes, and production environments. Tenancies share the same infrastructure and instances but keep data separate and private from other tenancies. I designed a set of common tenancy management APIs to allow setup and tear-down of tenancies and cleanup of tenancy data across participating micro-services. 

Finix Payments
==============
My Accomplishments at Finix Payments are as follows: 

* I led the Frontend Team to develop a complete Payments Dashboard redesign. I collaborated with Product Management and UX to define a customer-needs oriented redesign based upon understanding the target customers and their needs. The frontend was built using React. I led a backend-for-frontend (BFF) team called "Finix Web Services" that built UI-facing APIs in Java on SpringBoot and hosted in Kubernetes from AWS. The backend services empowered the frontend team to build higher performing user experiences and provided whitelabel embeddable components for customers. 

* My Finix Web Services Team built APIs to allow customers to do self-service signup for sandbox accounts. This generated sales leads to early stage clients. My team also built APIs and backends to allow self-service production account upgrades which automated much of the manual support operations, regulatory, and underwriting information gathering. The self-service signup integrated with my automated underwriting engine to allow for rapid onboarding of new merchants.

* My Compliance Team built Sub-Merchant PCI Compliance backends and public APIs to help vertical SaaS platform customers to manage their merchant's PCI compliance status. My team built a set of white-labeled hosted forms to allow merchants to invite their sub-merchants to attest to PCI regulations via a secure URL. My team built a management console to allow merchants to track the compliance status of their sub-merchants.

* My Finix Web Services Team built "Sub-Merchant Self-Service Signup Embeddable Forms" to allow sub-merchants of Finix Customers (SaaS Clients) to rapidly and automatically onboard new sub-merchants to their platforms. My team built a secure unique link distribution mechanism to allow Merchants to invite Sub-Merchants to sign-up. The signup link involved collecting 10+ pages of information and allowed the Sub-Merchant to revisit the link without the need for an account, gathering the data before submitting to the automated underwriting engine. My team built a sub-merchant signup integration API for the Merchant. My team built a monitoring dashboard for the Merchant to track their sub-merchant signup activities. This reduced the time-to-processing for payments on the Finix platform from multiple days to under 30 minutes.

* At Finix, my Underwriting Team built a new Automated Underwriting Engine in order to break away from the monolithic architecture and use DDD principles to speed up development and integration of many 3rd party verification services. The new underwriting engine was able to make an underwriting decision for a merchant within 30 seconds. I designed the configuration of the automated underwriting engine so that an MVP could be rapidly built and released, with the ability to add more complex underwriting rules and verification services later. The configuration was hierarchically parameterized using risk and financial tolerances so as to be configurable by machine learning algorithms. The engine was designed to be dynamically configurable at runtime, allowing for rapid changes to the underwriting rules and verification services used. The underwriting configuration was designed to be hierarchical, allowing for a global configuration to be inherited by a merchant's industry, and allow specific parameters to be customized for a specific merchant, or even a group of merchants categorized by their MCC. This allowed for a merchant to be provisioned with sensible defaults, and for the SaaS customer or sub-merchant to be able to override the defaults if necessary. 

* My Underwriting Team extended the new underwriting engine to integrate with GIACT and Persona in order to perform automatic identity verification for new merchants and their sub-merchants. 

* I led the development of a hosted configuration platform service. I brought my learnings from prior projects involving configuration and hosted shared multi-tenant services to lead my team to build a centralized configuration service to solve the many dynamic and inherited configuration needs of the Finix platform and its customers. These configuration needs included the ability to inherit sensible defaults from a global setting, or from a custom setting for a specific industry, or from a company's specific configuration that was inherited from the above. These settings all needed to be dynamically configurable at runtime. Settings could apply to underwriting rules and risk management, payment settlements configurations, white-labeled branding, payments processing configurations, and many other aspects of the Finix platform. The hosted Configuration Service provided an internal API to allow software systems to define any number of “configuration bundles” categories and their properties, and assign them to nodes in a hierarchical tree. The nodes are generally organized to correspond to the hierarchy of the Finix platform’s customers, the organizations they belong to, and the industries they operate in. For a specific node in the tree, the Configuration Service computes the property values of a Config Bundle that can either inherit or override properties from a same-category-named bundle of its node's parent nodes. The hosted Configuration Service allowed for complex sets of configurations to be centralized, reused, and updated at runtime. The hosted Configuration Service was built to be multi-tenant, allowing for rapid use by different development environments or different applications without the need for those environments to host their own configuration service. I had used multi-tenant hosted platform services at other companies to solve the common issue of a developer needing to set up a comprehensive environment of all services in order to do their development work. My hosted Configuration Service allowed for a developer to quickly set up a development environment with a minimal set of services and still be able to configure them to behave as if they were part of a larger system. This allowed for rapid development and testing of new features and services. Another advantage the Hosted Configuration Service offered was the simplicity provided for a developer to persist a configuration for their application code. Storing the configuration in the service required minimal developer effort and discouraged them from hard-coding or inventing their own non-dynamic configuration system. This provided a great boost to developer productivity. 

* I managed the Payments Settlements and Disputes team which integrated with WorldPay's Vantiv and Litle payments processors, and Elavon. I started managing this team when another Director of Engineering left the company. The CEO noted that this team had a long history of low performance. I worked with the team to understand their processes and evolve them to be more productive, predictable, and focused on the highest priorities. This took a lot of dedication to work closely with each individual engineer on the team in order to understand their concerns and find a way to change their attitude and gain their respect and buy-in in order to improve the whole team's working practices. Ultimately the team did improve and started delivering production features that were long overdue. 

Data Warehouse and ETL Platform Improvements at Finix Payments
==============================================================
My Data Engineering Team optimized the Data Engineering Pipeline and ETL framework to make Processing and Report Generation Performance Improvements. The team optimized the ETL and Data Warehousing design in order to increase successful report generation to 99.9% success rate. They reduced report latency from 45 minutes to under 3 minutes. I empowered the team to research alternative approaches to solving the performance issues. I suggested processing data in successive batches based upon elapsed time since the data entered the system, with the premise that older data changes less frequently than newer data. This idea was derived from how Java performs garbage collection. The team successfully implemented this approach using “materialized views” in AWS Redshift. I negotiated bandwidth with the business and sponsored the team to build a QA environment with test data that was representative of the production data. This allowed the team to test their changes and verify the performance improvements. I prioritized teamwork to resolve ETL issues and make batch processing failures recoverable in order to improve production quality metrics. 

Engineering Process Management and SOC-2 Compliance at Finix Payments
=====================================================================
At Finix Payments, I spearheaded Engineering Process Management to improve the engineering team's productivity and quality. I defined the engineering organization's development process to be SOC-2 Compliant. I worked with Finix's Compliance Officer to analyze SOC-2 compliance regulations. I analyzed current engineering practices and worked with lead engineers to understand their needs in order to make minimal changes to the process they wanted in order for it to be compliant. I determined that 95% of engineering practices were acceptable and documented a 'requirements traceability' matrix to illustrate how each compliance requirement was being met by the proposed working practices. I created developer-oriented documentation of the engineering process in order to be customer centric and simplify the practices to be followed by the developers. I made this documentation part of the standard developer onboarding training. The updated development process was designed to minimize impact on the current working practices and still be SOC-2 compliant. 
   
Optimizing and Overhauling The Payments Dashboard at Finix
==========================================================
Matching Scenarios: Tradeoff, Customer Focus, Impact, Strategy, Business Objectives
Situation: Payments dashboard was causing sales losses to prospective customers due to uninspiring design and bad user experience. 
The new UX team performed an extensive analysis and redesign of Finix’s Payments Dashboard - they spent ~6 months conducting this research and perfecting the design. 
Task: My team was asked to implement a complete redesign of the dashboard in 2 months due to upcoming sales demos and the need to expand our customer base to different types of customers. 
Action: Given the tight deadlines, I mentored my Front End Team Lead to rapidly identify and scope all of the work necessary to implement the new design. He had built the dashboard so was familiar with the implementation and had a good understanding of what would need to change. 
There were ~15 sections to the dashboard with up to 5 interactive screens in each section. We discussed how best to break down the scope and if it could be split by section / screen. 
He created and estimated the scope to implement and build automated tests for each new screen. 
I calculated that the project would take 7 months to implement. This was based upon the velocity of the team members that I had been tracking for the past 6 months. One senior team member had left the company and we had hired a junior engineer to replace him. 
I considered hiring contractors but given the tight deadlines we knew that they would not be able to ramp up quickly enough and would actually slow us down for most of the 7 week time-window remaining. 
I worked with the Product Manager to devise an MVP of the dashboard redesign. 
One aspect of the design was extraneous - an alternate way to access information. This accounted for an extra ⅓ of the scope. 
For the remaining scope, I suggested that we focus on overhauling the screens that would be used in sales demos first. 
We reduced the scope down to ~2.5 months. 
The team committed to working long hours to deliver the MVP
Result: I tracked the MVP scope and projected our progress on information radiators along with the other ~10 simultaneous projects that my other teams were implementing during that 2 month period. The team remained highly focused since we had Development Stories defined and scoped for every element of the work. I coached the Team Lead on keeping the team focused and energized. The new hire very quickly came up to speed and was highly energized by the challenge. I coached the other two engineers to mentor her and the energy and velocity of the team increased. The engineer who left the team was not a good influence on the team culture. I promoted the Team Lead to Manager once the project was successfully delivered. We adopted a new automated test framework (Cypress) which helped speed up implementation. With an all-hands on deck approach to production testing we were able to get the MVP released to production before the end-of-year code freeze. The CEO and prospective customers were delighted with the new dashboard design. 

Building The Automated Underwriting Engine at Finix
===================================================
Situation: Finix helps companies become fin-tech companies by integrating payments into their SaaS platforms. A key aspect of the payments stack is merchant underwriting. When a merchant fails to provide paid-for goods and services to an end-consumer, the charges can be disputed and refunded, especially when credit cards are used. If the merchant cannot make the refund, then Finix (the payments facilitator) is financially responsible. 1000’s of merchants go bankrupt every day in the US, so it is important that Finix carefully monitors and manages the sub-merchants of its customers. Finix’s strategy is to eliminate 99% of the manual merchant underwriting overhead by intelligently automating the process. Our objectives were to enable underwriting and provisioning for sub-merchant in less than 30 seconds, and eliminate manual effort so that Finix could radically cut the cost of performing underwriting. We had built an underwriting workflow and dashboard to support manual underwriting by our internal underwriters. The underwriting engine retrieved some information about each sub-merchant from a 3rd party service called GIACT. Our manual underwriting associates verified this information but could also spend up to an hour to verify additional information about a sub-merchant’s identity and credibility before approving, rejecting, or requesting more information from them. The business anticipated a flood of new sub-merchants due to a planned marketing campaign and recent large account addition (Chargebee). 
Task: My team was challenged to build automated underwriting within 3 months since Accurate global underwriting required integration of many 3rd party verification services that our manual team currently referenced on topics such as: 
* Individual Identity Verification
** All Individuals that own > 20% of the business
* Business Verification
** Business - MCC (Business Model)
** Bank Accounts
** Geographic Restrictions / Risk Profiles
*Compliance and History
** PCI compliance
** OFAC - screen list of sanctioned individuals
** AML - Anti Money Laundering
** Processing History
** Financial Stability
Action: I explained the business objectives to my team and we brainstormed a strategy to deliver upon the following:
* Business goals
** Reduce manual overhead
** Automated decision accuracy > 90%
* Technical goals
** Accelerate integration of new verification services to achieve accuracy
** Improve quality of releases, reduce risk, and decrease cost of maintenance
* Constraints and obstacles
** Small team of 4 engineers
** 3 months timeline to production
** The current design is cumbersome and difficult to modify or troubleshoot.
** Releases were risky due to a tightly coupled environment with a monolithic processing system.
** The original developers had left the company
** There was no technical documentation on the system
Considerations: The team wanted to work on an independent domain making developing and testing quicker and providing a clear bounded context to verify and integrate with other services. 
It is common for engineers to prefer to build new systems rather than extend existing systems. I’ve gone both ways on this reasoning in the past and it requires impartial, objective consideration. I decided that the case for building a new system was justified in this scenario.  
My Strategy: I needed to find a way to deliver automation quickly and find the capacity to build new. 
Design and deliver an automated MVP that would allow us to deliver automation in the short-term, but give us scope to replace it with a more sophisticated, feature-rich, and configurable implementation. Define a “black box” around the existing UW engine with APIs that would be compatible with the objectives of the new UW engine. Plan, design, and estimate scope to build a new automated underwriting engine. Collaborate on the strategy with business stakeholders to gain their sponsorship - CEO / PM / Underwriters. 
Execution Plan for Automated Underwriting MVP: I worked with the underwriting team to define the hard-coded automation parameters. I created a spreadsheet that calculated the effects of parameterized thresholds and weights on making underwriting decisions for Approved / Declined / Manual Review. Implement simple hard-coded automation logic inside the existing engine. 
Design the API to allow the UW Team to gain confidence in automated recommendations before enabling decisioning. 
Execution Plan for Underwriting Domain: Design, document, and review their proposed system architecture. HLSD Review Template - a strategic process I use to help my engineers think through Design Principles, Emergent Properties, and Non-Functional Requirements. Adopt DDD to reduce impact of changes to the processing monolith. Design a live production-integration strategy. Shadow-mode. Fall-back. Design framework to allow integration of new services via an “SPI adapter”. This eliminates all the complexity of configuration and uses simple code instead that integrates with a cleanly defined interface. Design parameterized APIs to allow fine-tuning either manually or via machine-learning. Define the underwriting workflow configuration to be hierarchical and based upon groups so it could be inherited and reused for types of businesses (MCCs / Geo / etc). 
Result and Retrospective: 
* Automated Underwriting MVP recommendations were provided to the underwriters within 6 weeks. 
* The team estimated the scope to build and integrate the new engine and we defined milestones of completion in 4 months, followed by 2 months of testing and production integration. 
* The new engine was built and fully deployed in < 6 months. Independent of the monolith with clean APIs / Bounded Context. Built using K8s and Java SpringBoot. 
* We also built a core platform service to manage dynamic hierarchical configurations and evangelized its usage amongst the other engineering teams. 
* I asked the team to plan for deployment rollout and quality monitoring. The team planned a phased deployment of the new engine into production running in parallel with the old underwriting engine to gain confidence in system reliability and consistency. In order to achieve this, we built an adapter ‘gateway’ to allow a per-customer roll-out. 
Change in Responsibilities: At this time, I inherited 2 new teams and had to step back from the project. This was a great opportunity for me to see how my engineering process performed when I was not deeply embedded with the team. The underwriting team had adopted my practices over the previous 12 months. This was a great opportunity for me to coach the lead-engineer and for him to grow and prove he could lead a large initiative. I met with my team-leads every week for updates, attended design review meetings, and reviewed system design documentation to ensure the team was being rigorous and the designs were focused upon solving the objectives. I documented the responsibilities and expectations of the role for my Team Leads
Stepping-In to help: I saw that the team was spending many days debating the best approach and I was concerned they were not making progress. I consulted with the team lead on the progress they were making. Two of the engineers debated many of the technical decisions and the more senior engineers felt it was not necessary. I assured them that debate was great and to stay open minded and keep debating. I coached the team-lead on mentoring the junior engineers to understand where decisions could be revisited so long as concepts were abstracted. I also reminded them that he was more senior and to be inclusive and curious as to the ideas presented by the junior engineers. I reminded him that it is often important to understand and explain and consider the pros and cons of each technical option to junior engineers. My team-lead found it hard to mentor the 2 junior engineers - who were very smart and confident but lacking experience - so I offered to step in and help escalate the schedule...I met with the team and reminded them of the schedule we had agreed to. I gave them a milestone to present their design to me in 3 days. They soon started making decisions! We celebrated the completion of the design phase and the team started implementation. I continued to have 1:1 meetings with all of my team-members, but I asked my team-leads to alternate 1:1s with me since I had inherited a larger engineering organization. Morale was much improved and the team was working well together. 
* At one point after deploying the Automation MVP, there was some frustration from the underwriters with how the new system was operating. I stepped back in to help with communications. I worked with the underwriting lead to understand the issues. One cause was a specific new customer who’s merchants were found to be highly risky and fraudulent. The automated decisions were correctly flagging them for review. Also, it transpired that an independent pager-duty had been deliberately established to notify the underwriters about this specific customer’s sub-merchants boarding requests so they could be diligent. This pager had not been disabled and was causing confusion when the system had automatically underwritten the sub-merchants. 
Success Metrics
* There were zero production incidents caused by the deployment rollout. 
* A new verification service was successfully integrated in one sprint. (Persona) This demonstrates the success of the new system design. 
There has not been a single production incident caused by the new implementation in 8 months. This demonstrates the success of the robust development process.


Defining and Managing the Root Cause Analysis Process at Finix 
==============================================================
At Finix Payments, I defined, documented, and fostered a consistent and effective the Root Cause Analysis (RCA) process. I created an easy to use RCA template that helped guide engineers to identify the true root causes. I defined a section within the production ticket where engineers who were actively working on an incident would record significant observations, hypotheses, findings, and actions. In addition to this providing a clear status and for others to understand (as opposed to sifting through 1000's of Slack messages), it provided a clean timeline for the RCA report. My RCA template guided engineers and manager to objectively  identify layers of root causes to issues until a fundamental and actionable cause was found. A fundamental premise of the analysis was that humans could never be blamed as a root cause. Instead, it must be assumed that a single human is expected to make errors, and a process must be put in place to verify the actions taken by a human, such as automated verification, peer review, or preferably both. My RCA template had a list of Action Items that would be documented as the RCA session was conducted. Each Action Item had to be represented by a JIRA work ticket, linked to the main ticket, and tagged as a specific ticket type so they could be tracked and reviewed on a dashboard. These often represented tech-debt items that would be the root causes contributing to multiple incidents. The priority and urgency of these tech-debt tickets could be escalated as necessary. 

Release Management Process and Practices at Finix Payments
==========================================================
At Finix Payments, I led and defined the Release Management process and practices. I worked with the quality engineers, business stakeholders, and engineers to define a release process that would allow the quality team to manage risk by controlling the complexity of each release. Source changes needed to be grouped into functional branches so their release schedule could be controlled, verified, and released according to the business timeline priorities. I used my learnings from prior companies to move the release process towards a release-when-ready vs a cadence of releasing uncoordinated changes that were committed. Although I was able to change the working practices of my teams over time, I met stubborn resistance from long-tenured engineers at the company who were not experienced working in a larger engineering team. Although I was not at Finix long enough to fully implement the release process, I was able to make significant improvements to the release process and practices for my teams. I resolved to accept that the solution needed to be local and started working towards implementing a Domain Driven Design for my team's services. This allowed my teams to work more independently from other team practices that were outside of my influence. I believe that sometime it is not possible to have wholesale influence over an organization but you can "show the way" by demonstrating the benefits of a better way of working and other teams may adopt my practices when they are curious to understand how my teams are more productive than theirs. 

Project Estimation and Delivery Tracking at Finix Payments
==========================================================
At Finix Payments, I championed Project Estimation and Project Delivery Tracking for my teams. I built multiple spreadsheets to help my teams estimate and project their velocity and capacity for delivery over an extended timeframe (3-9 months). The spreadsheets projected the assignment allocation of each engineer to each project deliverable. It even allowed for team-members that were yet to be hired to be factored into the estimation. It allowed for engineers to have different performance capabilities to simulate ramp-up time, partial allocation, PTO, or differentiate junior engineers capabilities from high-performers. This spreadsheet tool allowed us to identify and break up large projects down to more feasible deadlines. It clearly illustrated the capacity and allocation of the team and allowed for rapid macro planning. This enabled mission-critical MVP projects to be delivered predictably. One example of this was the large overhaul of the Payments Dashboard. The project was estimated to take 7 months, but the business needed it in 3 months. I used the spreadsheet to identify the critical path and the team was able to deliver the MVP in 3 months. The team then continued to deliver the remaining features over the next 4 months. This gave team-members a voice and reasonable plan to deliver to, which earned their commitment and they worked very hard to deliver. I projected project burn-down charts on TV’s in the office, which gamified the delivery of projects and boosted the team's morale, motivation, and commitment to delivery. It also highlighted that some team-members were not delivering and allowed me to coach them to improve their performance. In a couple of instances, the low performing engineers were not coachable and were put on performance improvement plans. When the did not improve, they were let go. 

People Management at Finix Payments
===================================
At Finix Payments, I managed several teams who's total headcount was over 30. I coached 4 lead engineers to become managers. I clearly defined and documented the roles for "Engineering Manager", "Lead Engineer", and "Tech Lead" so that the engineers could understand their career path and expectations for each role. I refined the company's Performance Evaluation and Promotion Rubric. I refined and defined the Engineering rubric for levels IC1 - IC6. I coached my teams through the promotion and leveling rubric and referred to it regularly in 1:1 meetings, promotions, and compensation adjustment discussions. I built a spreadsheet to track IC levels across the engineering organization’s teams and used it for performance calibration across multiple engineering director's orgs. Finix used the spreadsheet to negotiate compensation adjustments, balance the talent across the engineering organization, and to retain the best performers. I built a spreadsheet to gauge each engineer's performance against 20+ traits, allowing a profile of each team-member to be easily maintained and visualized. This helped quantify and personalize the areas for improvement of each team-member and gave an overall perspective of the balance of traits across each engineering team. 

